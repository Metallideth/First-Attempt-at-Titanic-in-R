---
title: "TitanicFirstTry"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r load libraries and data}
library(tidyverse)
library(stringr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)

train <- read.csv("train.csv")
test <-  read.csv("test.csv")
train <- as_tibble(train)
test <- as_tibble(test)

summary(train)
```

Age appears to have NA's

Let's add a feature for title

```{r add Title}
train <- mutate(train, Title = 
                  gsub("^.*, (.*?)\\..*$", "\\1",as.character(Name)))
test <- mutate(test, Title = 
                 gsub("^.*, (.*?)\\..*$", "\\1",as.character(Name)))
train <- select(train, -c(PassengerId,Cabin,Ticket))
test <- select(test, -c(PassengerId,Cabin,Ticket))
train[train$Embarked =="",]$Embarked <- "S" #assign the mode
```

We'll fix the ages later
In the meantime, let's see how certain variables affect survival

```{r first ggpairs}
ggpairs(data = select(train,-Name))
```

Too many levels in Title.

```{r}
summary(with(train, aov(Survived ~ Title)))
```

Title is significant, clearly

```{r plot Title}
ggplot(data = train, aes(x = Title, y = Survived)) + geom_bar(
    stat = "summary", fun.y = mean) + coord_flip() +
    geom_text(aes(label = ..count.., y= ..prop..), 
    stat= "count", hjust = 1, col = "blue")
```

Some of these could certainly be combined - try Mrs and Miss, Mr and Master

```{r proportion tests}

Mrs <- filter(train, Title %in% c("Mrs"))
Miss <- filter(train, Title %in% c("Miss"))
counts <- c(dim(filter(Mrs))[1],dim(filter(Miss))[1])
lived <- c(dim(filter(Mrs,Survived == 1))[1],dim(filter(Miss,Survived == 1))[1])

Mr <- filter(train, Title %in% c("Mr"))
Master <- filter(train, Title %in% c("Master"))
counts2 <- c(dim(filter(Mr))[1],dim(filter(Master))[1])
lived2 <- c(dim(filter(Mr,Survived == 1))[1],dim(filter(Master,Survived == 1))[1])

prop.test(lived,counts)$p.value
prop.test(lived2,counts2)$p.value

```

I'll assume a strict(er) standard here, 90% significance.

At 90% significance we would reject both null hypotheses that these means are the same, so we should not merge them.

None of the rest of the "Title" values have a sufficient number of values to run statistical tests. Thus, title will merge the following:

Gentlelady <- the Countess, Ms, Mrs, Mme, Mlle, Lady
Miss
Gentleman <- Sir, Master, Major, Dr, Col
Mr <- Rev, Mr, Jonkheer, Don, Capt

In the test set, we'll go with

Gentlelady <- Ms, Mrs
Miss <- Dona, Miss
Gentleman <- Master, Dr, Col
Mr <- Mr, Rev

```{r grouping Titles}
train <- train %>% 
  mutate(Title = replace(Title, Title %in% c("the Countess", "Ms", "Mrs", "Mme", "Mlle", "Lady"),"Gentlelady")) %>% 
  mutate(Title = replace(Title, Title %in% c("Sir", "Master", "Major", "Dr", "Col"),"Gentleman")) %>% 
  mutate(Title = replace(Title, Title %in% c("Rev", "Mr", "Jonkheer", "Don", "Capt"),"Mr"))
  
test <- test %>% 
  mutate(Title = replace(Title, Title %in% c("Ms", "Mrs"),"Gentlelady")) %>% 
  mutate(Title = replace(Title, Title %in% c("Dona", "Miss"),"Miss")) %>% 
  mutate(Title = replace(Title, Title %in% c("Master", "Dr", "Col"),"Gentleman")) %>% 
  mutate(Title = replace(Title, Title %in% c("Mr", "Rev"),"Mr"))

ggplot(data = train, aes(x = Title, y = Survived)) + geom_bar(
    stat = "summary", fun.y = mean) + coord_flip() +
    geom_text(aes(label = ..count.., y= ..prop..), 
    stat= "count", hjust = 1, col = "blue")

```

That's more like it. Let's check Miss vs. Gentlelady just to be sure...

```{r Miss vs. Gentlelady}
Gentlelady <- filter(train, Title %in% c("Gentlelady"))
Miss <- filter(train, Title %in% c("Miss"))
counts <- c(dim(filter(Gentlelady))[1],dim(filter(Miss))[1])
lived <- c(dim(filter(Gentlelady,Survived == 1))[1],dim(filter(Miss,Survived == 1))[1])

prop.test(lived,counts)$p.value
```

P-value is lower than before, indicating that the probabilities of survival for these groups is even more divergent.

Now we need to fill in Age. First, I'll look at the distribution of age and see if the NAs appear to be drawn from the same population using inferential statistics.

```{r complete Age field}
summary(train)
summary(test)

unadjAge <- ggplot(data = subset(train,!is.na(Age)), aes(x = Age)) + geom_histogram(binwidth = 2)

```

Age is skewed right, so we should probably transform it to be normal so it has better regression properties.

```{r Age field transformed}
logAge <- ggplot(data = subset(train,!is.na(Age)), aes(x = log(Age))) + geom_histogram(binwidth = 1/10)
sqrtAge <- ggplot(data = subset(train,!is.na(Age)), aes(x = sqrt(Age))) + geom_histogram(binwidth = 1/5)
otherpowerAge <- ggplot(data = subset(train,!is.na(Age)), aes(x = Age^0.2)) + geom_histogram(binwidth = 1/20)

grid.arrange(unadjAge,logAge,sqrtAge,otherpowerAge,nrow = 1)
```

There's still a great deal of skew to square root. As shown below, a slightly higher power is warranted

```{r Age frequency polygon}
trainagesubset <- subset(train,!is.na(Age))
numpowers <- length(seq(0.1,1,by=0.1))
exponent <- rep(seq(0.1,1,by=0.1),each = dim(trainagesubset)[1])
agerep <- rep(trainagesubset$Age,times = numpowers)
transformage <- data.frame(exponent = as.factor(exponent),transage = agerep^exponent)

ggplot(data = transformage, aes(x = transage)) + geom_freqpoly(aes(color = exponent),bins = 100) +
  coord_cartesian(xlim = c(0,40))

ggplot(data = transformage, aes(x = transage)) + geom_histogram(aes(fill = exponent,color = exponent),bins = 100) + coord_cartesian(xlim = c(0,40))

#ggplot(data = transformage, aes(x = transage)) + geom_area(aes(y = ..count..,fill = exponent), stat = "bin", color = "black", alpha = 0.3, bins = 50)
```

The best exponent appears to be somewhere close to 0.7. To get more specific, let's run a Shapiro-Wilk test on a range of values close by.

```{r}
params <- rep(seq(0.6,0.9,by=0.01),each = dim(trainagesubset)[1])
params <- data.frame(matrix(params,nrow = dim(trainagesubset)[1]))
shapiroparams <- trainagesubset$Age ^ params
shapiroresults <- apply(shapiroparams,2,function(x) shapiro.test(x)$p.value)
maxindex <- which.max(shapiroresults)
exponent <- seq(0.6,0.9,by=0.01)[maxindex]

exponent
```

Looks like an exponent of `r exponent` is returned. Let's check and see what that looks like.

```{r}
ideal <- ggplot(data = train,aes(x = Age ^ exponent)) + geom_histogram()
less <- ggplot(data = train,aes(x = Age ^ 0.5)) + geom_histogram()
more <- ggplot(data = train,aes(x = Age)) + geom_histogram()

grid.arrange(ideal,less,more, nrow = 1)
```

Not very normal, which makes sense considering p-value of `r shapiroresults[maxindex]`. We'll make do with leaving age untransformed.

```{r}
AgeNA <- filter(train, is.na(Age))
AgeNotNA <- filter(train, !is.na(Age))
counts4 <- c(dim(filter(AgeNA))[1],dim(filter(AgeNotNA))[1])
lived4 <- c(dim(filter(AgeNA,Survived == 1))[1],dim(filter(AgeNotNA,Survived == 1))[1])

prop.test(lived4,counts4)

```

It looks like on a raw basis the ratios are different. It's hard to tell if this means that we can't impute Age, considering other variables might be different. We could investigate this using pairwise analysis but let's go ahead and impute the values with the MICE package.

```{r}

```


```{r ggpairs again}
trainmod <- train
trainmod$Survived <- as.factor(trainmod$Survived)
trainmod$Pclass <- as.factor(trainmod$Pclass)
trainmod <- select(trainmod,-Name)
ggpairs(data = trainmod,upper = list(continuous = "cor",discrete = "facetbar",combo = "box_no_facet"),lower = 
          list(combo = "facethist",discrete = "facetbar",continuous = "points"),axisLabels = "internal")

```

From this, I can see a lot. Survival is much lower among Pclass 3, and slightly higher in Pclass 1. The age of those who survived skews younger. Males died with very high frequency, and females had a higher frequency of survival. SibSp doesn't seem to have a dramatic effect, whereas Parch does. Fare skews higher among the survivors, and embarkation port appears to significantly affect survival.

However, it is clear upon further reflection that a lot of these independent variables are correlated. Considering the small dataset and number of features, I think it's unlikely that there will be overfitting here, but it's something to look out for during cross-validation.

